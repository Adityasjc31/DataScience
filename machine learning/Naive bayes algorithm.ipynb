{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 25/10/23 - Implementation of Naive Algo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 26/10/23 - Naive Bayes Algorithms\n",
    "- Used Just for classification\n",
    "- Kind : Supervised\n",
    "- Bayes theorem : P(A/B) = P(B/A) * P(A)/P(B)\n",
    "    - Here,\n",
    "     - A - Hypothesis\n",
    "     - B - Evidence\n",
    "     - P(A) - Prior probability.It is the probability of occurence of the hypothesis\n",
    "     - P(B) - Marginal probability.It is the probability of occurence of the evidence\n",
    "     - P(B/A) - Likelihood. It is the probability of occurence of B given that A has already occurred\n",
    "     - P(A/B) - Posterior probability. It is the probability of occurence of A given that B has already occurred\n",
    "- Assumptions : Data are independent of each other where in actual it is not\n",
    "- It is parametric Kind\n",
    "<hr>\n",
    "\n",
    "## Feature Engineering\n",
    "Creating new feature by combining two or more feature.\n",
    "Example: Creating a new feature called \"Age\" from \"Years\" and \"Months\".\n",
    "This process is required only in machine learning and not in deep learning\n",
    "<hr>\n",
    "\n",
    "## Advanced techniques\n",
    "\n",
    "There are many things that can be done to improve this basic model. These techniques allow Naive Bayes to perform at the same level as more advanced methods. Some of these techniques are:\n",
    "\n",
    "- Removing stopwords: These are common words that don’t really add anything to the classification, such as a, able, either, else, ever and so on. So for our purposes, The election was over would be election over and a very close game would be very close game.\n",
    "\n",
    "- Lemmatizing words: This is grouping together different inflections of the same word. So election, elections, elected, and so on would be grouped together and counted as more appearances of the same word.\n",
    "\n",
    "- Using n-grams: Instead of counting single words as we did here, we could count sequences of words, like “clean match” and “close election”.\n",
    "\n",
    "- Using TF-IDF: Instead of just counting frequency we could do something more advanced like also penalizing words that appear frequently in most of the texts."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
